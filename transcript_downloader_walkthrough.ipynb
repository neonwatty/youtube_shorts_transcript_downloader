{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jermwatt/youtube_transcript_downloader/blob/main/transcript_downloader_walkthrough.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# if running in collab pull repo and install requirements\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    !git clone https://github.com/jermwatt/youtube_transcript_downloader.git\n",
    "    %cd youtube_transcript_downloader\n",
    "    !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube transcript downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem:\n",
    "- this pro youtuber [has downloaded THOUSANDS of youtube shorts transcripts BY HAND](https://youtu.be/As7abwNhG7Y?si=dSzEf6Hk0glROYhu&t=340) to analyze them\n",
    "- each time required adjusting the shorts url to a standard format (where transcripts live), clicking around buttons to show the transcript, and then copying and pasting that text somewhere\n",
    "- lets say 60 secs per video to do all this - for 6000 videos that's 100 hours of manual labor there\n",
    "- let's help anyone else in the future who wants to do this save a bunch of time\n",
    "\n",
    "\n",
    "Let's build:\n",
    "- a simple app you can run locally or via a free service that lets you\n",
    "- upload a .txt file with youtube shorts urls, transform the url to the standard youtube viewer, and extracts their transcripts\n",
    "- once complete lets you download a .csv or .xlsx file with the transcripts nicely organized by url / video id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do build this in 3 steps.  These are:\n",
    "\n",
    "1.  I/O functionality to upload shorts urls and download associated transcripts\n",
    "2.  type and formatting checks to ensure user inputs are proper shorts urls\n",
    "3.  a way to to pull youtube shorts transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  I/O functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- first lets design simple I/O functionality\n",
    "- we'll allow our users to upload `.txt` files containing shorts urls\n",
    "- one url per line\n",
    "- an input `.txt` file can look like this\n",
    "\n",
    "```text\n",
    "https://www.youtube.com/shorts/xaRRZKgj5aQ\n",
    "https://www.youtube.com/shorts/xK9_V9LF4PE\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- our function for loading input will be called `parse_input_file`\n",
    "- it takes in a file path, reads in the file, and stores each line in an output list\n",
    "- our function for saving output will be called `save_output`\n",
    "- it will save the output - which will contain urls, video ids, and video transcripts - as `csv` file using `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def parse_input_file(input_file_path: str) -> list:\n",
    "    youtube_urls = []\n",
    "    with open(input_file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            youtube_urls.append(line.strip())\n",
    "    return youtube_urls\n",
    "\n",
    "\n",
    "def save_output(data: list, output_file_path: str) -> None:\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Type and formatting checks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we need to ensure that input contains valid shorts urls\n",
    "- no point in trying to pull transcripts from an invalid url\n",
    "- a single function `is_valid_youtube_shorts_url` checks the type of each line, and uses a shorts regular expression pattern to validate that the input matches a shorts url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def is_valid_youtube_shorts_url(url: str) -> bool:\n",
    "    if not isinstance(url, str):\n",
    "        return False\n",
    "    pattern = r\"^https://www\\.youtube\\.com/shorts/[A-Za-z0-9_-]{11}$\"  # youtube vido ids are always 11 chars long\n",
    "    return re.match(pattern, url) is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.  Pulling youtube shorts transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we'll create simple wrappers on the fantastic [youtube_transcript_api](https://github.com/jdepoix/youtube-transcript-api) to pull transcripts, which wraps around the requests library\n",
    "- it has a built in batch mode &#x1f929; - so we can pull multiple video transcripts at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- simple functionality below to fetch one or multiple transcripts\n",
    "    - `get_single_transcript` pulls the transcript of a single video\n",
    "    - `get_batch_transcripts` pulls transcripts of multiple input videos\n",
    "\n",
    "- note: we won't have to transform the shorts url as described in [the motivating video](https://youtu.be/As7abwNhG7Y?si=dSzEf6Hk0glROYhu&t=340) - all we need are the video ids to gather the transcripts\n",
    "- more manual labor saved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "\n",
    "def get_single_transcript(youtube_url: str) -> dict:\n",
    "    try:\n",
    "        if is_valid_youtube_shorts_url(youtube_url):\n",
    "            video_id = youtube_url.split(\"/\")[-1]\n",
    "            video_transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "            entry = {}\n",
    "            entry[\"youtube_url\"] = youtube_url\n",
    "            entry[\"video_id\"] = video_id\n",
    "            entry[\"transcript\"] = video_transcript\n",
    "            return entry\n",
    "        else:\n",
    "            print(f\"FAILURE: youtube_url is not valid - {youtube_url}\")\n",
    "            return {}\n",
    "    except Exception as e:\n",
    "        print(f\"FAILURE: transcript pull for youtube_url - {youtube_url} - failed with exception {e}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "def get_batch_transcripts(youtube_urls: List[str]) -> List[Dict]:\n",
    "    valid_urls = []\n",
    "    valid_vids = []\n",
    "    for i, url in enumerate(youtube_urls):\n",
    "        if is_valid_youtube_shorts_url(url):\n",
    "            vid = url.split(\"/\")[-1]\n",
    "            valid_urls.append(url)\n",
    "            valid_vids.append(vid)\n",
    "    try:\n",
    "        video_transcripts = YouTubeTranscriptApi.get_transcripts(valid_vids, languages=[\"en\"])[0]\n",
    "        entries = []\n",
    "        for i in range(len(valid_urls)):\n",
    "            entry = {}\n",
    "            entry[\"youtube_url\"] = valid_urls[i]\n",
    "            entry[\"video_id\"] = valid_vids[i]\n",
    "            entry[\"transcript\"] = video_transcripts[valid_vids[i]]\n",
    "            entries.append(entry)\n",
    "        return entries\n",
    "    except Exception as e:\n",
    "        print(f\"FAILURE: batch transcription fetch failed with exception {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test transcript pull functionality with two test videos\n",
    "youtube_url_1 = \"https://www.youtube.com/shorts/xaRRZKgj5aQ\"\n",
    "single_transcript = get_single_transcript(youtube_url_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test our functionality with two videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test transcript pull functionality with two test videos\n",
    "youtube_url_1 = \"https://www.youtube.com/shorts/xaRRZKgj5aQ\"\n",
    "youtube_url_2 = \"https://www.youtube.com/shorts/xK9_V9LF4PE\"\n",
    "youtube_urls = [youtube_url_1, youtube_url_2]\n",
    "single_transcript = get_single_transcript(youtube_url_1)\n",
    "batch_transcripts = get_batch_transcripts(youtube_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'youtube_url': 'https://www.youtube.com/shorts/xaRRZKgj5aQ', 'video_id': 'xaRRZKgj5aQ', 'transcript': [{'text': 'what happens if you pull a shot of', 'start': 0.08, 'duration': 2.839}, {'text': 'espresso through an orange I thought', 'start': 1.24, 'duration': 3.119}, {'text': 'this could potentially taste pretty good', 'start': 2.919, 'duration': 2.801}, {'text': \"so let's try it out and see if \n"
     ]
    }
   ],
   "source": [
    "# print the first few hundred characters of return object\n",
    "print(str(single_transcript)[:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lets put it all together\n",
    "- we upload a test file of input youtube shorts urls (we'll print it out below)\n",
    "- then we use `get_batch_transcripts`\n",
    "- finally we save the result using `save_output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.youtube.com/shorts/xaRRZKgj5aQ\\n', 'https://www.youtube.com/shorts/xK9_V9LF4PE\\n', 'https://www.youtube.com/shorts/1RV8RhUvJjo\\n']\n"
     ]
    }
   ],
   "source": [
    "# print out first few lines of input\n",
    "with open(\"data/input/test_input.txt\") as myfile:\n",
    "    first_few_lines = myfile.readlines(1024)[0:3]\n",
    "print(first_few_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test functionality\n",
    "input_file_path = \"data/input/test_input.txt\"\n",
    "output_file_path = \"data/output/test_output.csv\"\n",
    "youtube_urls = parse_input_file(input_file_path)\n",
    "batch_transcripts = get_batch_transcripts(youtube_urls)\n",
    "save_output(batch_transcripts, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lets check the output by printing out the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>youtube_url</th>\n",
       "      <th>video_id</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.youtube.com/shorts/xaRRZKgj5aQ</td>\n",
       "      <td>xaRRZKgj5aQ</td>\n",
       "      <td>[{'text': 'what happens if you pull a shot of'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.youtube.com/shorts/xK9_V9LF4PE</td>\n",
       "      <td>xK9_V9LF4PE</td>\n",
       "      <td>[{'text': 'here are snacks I packed for my fli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  youtube_url     video_id  \\\n",
       "0  https://www.youtube.com/shorts/xaRRZKgj5aQ  xaRRZKgj5aQ   \n",
       "1  https://www.youtube.com/shorts/xK9_V9LF4PE  xK9_V9LF4PE   \n",
       "\n",
       "                                          transcript  \n",
       "0  [{'text': 'what happens if you pull a shot of'...  \n",
       "1  [{'text': 'here are snacks I packed for my fli...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(output_file_path).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlit app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this functionality is wrapped up into an easy to use streamlit app\n",
    "- to run locally just type this at your terminal\n",
    "\n",
    "```bash\n",
    "python -m streamlit run youtube_shorts_transcript_downloader/app.py\n",
    "```\n",
    "\n",
    "- to run via HF Spaces click this tab [![HuggingFace Space](https://img.shields.io/badge/ðŸ¤—-HuggingFace%20Space-cyan.svg)](https://huggingface.co/spaces/neonwatty/youtube_shorts_transcript_downloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
